# ─── LLM (Local) ───
# Path to a GGUF model file on disk
# Download e.g.: huggingface-cli download TheBloke/Meta-Llama-3-8B-Instruct-GGUF Meta-Llama-3-8B-Instruct-Q4_K_M.gguf
LLAMA_MODEL_PATH=./models/Meta-Llama-3-8B-Instruct-Q4_K_M.gguf
LLM_CONTEXT_LENGTH=4096
LLM_MAX_TOKENS=512
LLM_TEMPERATURE=0.1
LLM_GPU_LAYERS=-1

# ─── Embeddings ───
EMBEDDING_MODEL=BAAI/bge-large-en-v1.5
EMBEDDING_DIMENSION=1024
EMBEDDING_DEVICE=cuda

# ─── Reranker ───
RERANKER_MODEL=BAAI/bge-reranker-large

# ─── Retrieval ───
TOP_K=5
RERANK_TOP_K=20
DENSE_WEIGHT=0.6
SPARSE_WEIGHT=0.4
RRF_K=60

# ─── FAISS ───
FAISS_INDEX_PATH=./data/faiss_index
FAISS_USE_GPU=true

# ─── BM25 ───
BM25_INDEX_PATH=./data/bm25_index.pkl

# ─── Chunking ───
CHUNK_SIZE=512
CHUNK_OVERLAP=64

# ─── Security ───
JWT_SECRET=change-this-to-a-strong-random-secret
JWT_ALGORITHM=HS256
ACCESS_TOKEN_EXPIRE_MINUTES=60
RATE_LIMIT_REQUESTS=30
RATE_LIMIT_WINDOW_SECONDS=60

# ─── Data ───
DOCUMENTS_DIR=./data/documents
IMAGES_DIR=./data/images
METADATA_DB_PATH=./data/metadata.db
USERS_DB_PATH=./data/users_db.json
